{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7f8600-d50e-4df6-8e3b-ea68510c1589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# platform\n",
    "from importlib_metadata import version\n",
    "import platform\n",
    "print('The Python version is {}.'.format(platform.python_version()))\n",
    "\n",
    "import numpy as np\n",
    "print('The numpy version is {}.'.format(version('numpy')))\n",
    "\n",
    "import rasterio\n",
    "print('The rasterio version is {}.'.format(version('rasterio')))\n",
    "\n",
    "import torch\n",
    "print('The torch version is {}.'.format(version('torch')))\n",
    "from torch.nn import functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "print('The pytorch_lightning version is {}.'.format(version('pytorch_lightning')))\n",
    "import matplotlib.pyplot as plt\n",
    "print('The matplotlib version is {}.'.format(version('matplotlib')))\n",
    "\n",
    "# additional basic packages\n",
    "import random\n",
    "import time\n",
    "\n",
    "# Nvidia card present\n",
    "!nvidia-smi -L\n",
    "time.sleep(0.5)\n",
    "# run on as many GPUs as available by default\n",
    "pl.Trainer(accelerator=\"auto\", devices=\"auto\", strategy=\"auto\")\n",
    "\n",
    "# data paths\n",
    "feature_file_path = 'data/FeatureFile_230628.tif'\n",
    "label_file_path = 'data/LabelFile_230628.tif'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2e2ab9",
   "metadata": {},
   "source": [
    "Loading the files for Features and Labels. The bands are as follows:\n",
    "1. t-1 b8 (reducer median, pre fire)\n",
    "2. t-1 b12 (reducer median, pre fire)\n",
    "3. t b8 (post fire)\n",
    "4. t b12 (post fire)\n",
    "5. t clouds (from CloudSen, post fire)\n",
    "6. t shadows (from CloudSen, post fire)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e45681b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_geotiff(file_path, band_number=1):\n",
    "    with rasterio.open(file_path) as file:\n",
    "        print(f'File: {file_path}')\n",
    "        print(f'Number of bands: {file.count}')\n",
    "        print(f'Dimensions: {file.width} x {file.height}')\n",
    "        print(f'CRS: {file.crs}')\n",
    "        print(f'Data type: {file.dtypes[0]}')\n",
    "\n",
    "        band_data = file.read(band_number)\n",
    "        unique_values = np.unique(band_data)\n",
    "        print(f'Unique values in band {band_number}: {unique_values}')\n",
    "        \n",
    "        plt.imshow(band_data, cmap='gray')\n",
    "        plt.colorbar(label=f'Band {band_number} Value')\n",
    "        plt.title(f'{file_path} - Band {band_number}')\n",
    "        plt.show()\n",
    "\n",
    "# Usage:\n",
    "analyze_geotiff(feature_file_path)\n",
    "analyze_geotiff(label_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f1de3b",
   "metadata": {},
   "source": [
    "Now it's time to split the data into small batches. Because of memory limitations we will create a custom dataloader which loads everything on demand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eca1ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BadnetDataset(Dataset):\n",
    "    def __init__(self, feature_file_path, label_file_path, chip_size=64, overlap=0):\n",
    "        self.feature_file_path = feature_file_path\n",
    "        self.label_file_path = label_file_path\n",
    "        \n",
    "        # Open the files temporarily just to get the dimensions\n",
    "        with rasterio.open(self.feature_file_path) as feature_file, \\\n",
    "             rasterio.open(self.label_file_path) as label_file:\n",
    "            \n",
    "            self.width, self.height = feature_file.width, feature_file.height\n",
    "        \n",
    "        # Define the chip size, overlap, and padding value\n",
    "        self.chip_size = chip_size\n",
    "        self.overlap = overlap\n",
    "        \n",
    "        # Calculate the number of chips in each dimension\n",
    "        self.step_size = self.chip_size - self.overlap\n",
    "        self.chips_x = (self.width - self.overlap) // self.step_size\n",
    "        self.chips_y = (self.height - self.overlap) // self.step_size\n",
    "        \n",
    "    def __len__(self):\n",
    "        # Total number of chips in the dataset\n",
    "        return self.chips_x * self.chips_y\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Calculate the chip coordinates based on the index\n",
    "        chip_y, chip_x = divmod(idx, self.chips_x)\n",
    "        col = chip_x * self.step_size\n",
    "        row = chip_y * self.step_size\n",
    "        \n",
    "        \n",
    "        # Define the window size (with overlap)\n",
    "        window_size = self.chip_size + self.overlap\n",
    "        \n",
    "        # Read a window from each file\n",
    "        with rasterio.open(self.feature_file_path, mode='r') as feature_file, \\\n",
    "             rasterio.open(self.label_file_path, mode='r') as label_file:\n",
    "            # Read a window from each file\n",
    "            feature_window = feature_file.read(window=rasterio.windows.Window(col, row, window_size, window_size))\n",
    "            label_window = label_file.read(window=rasterio.windows.Window(col, row, window_size, window_size))\n",
    "        \n",
    "        # Convert the numpy arrays to a supported data type\n",
    "        feature_window = feature_window.astype(np.float32)\n",
    "        label_window = label_window.astype(np.int32)\n",
    "        \n",
    "        # Convert the windows to PyTorch tensors\n",
    "        feature_tensor = torch.tensor(feature_window)\n",
    "        label_tensor = torch.tensor(label_window)\n",
    "        \n",
    "        label_tensor = label_tensor.squeeze(0)  # Remove the channel dimension if it exists\n",
    "        return feature_tensor, label_tensor\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791190f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = BadnetDataset(feature_file_path, label_file_path)\n",
    "_, lab = ds[1063]\n",
    "plt.imshow(lab)\n",
    "prob = sum(lab.flatten()) / (lab.shape[0] * lab.shape[1])\n",
    "print(f'Probability of positive label: {prob}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b799cc24",
   "metadata": {},
   "source": [
    "Test the Dataset and Dataloader class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b41e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the dataloader\n",
    "dataset = BadnetDataset(feature_file_path, label_file_path, chip_size=64, overlap=0)\n",
    "test_dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "train_features, train_labels = next(iter(test_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2978f3a4",
   "metadata": {},
   "source": [
    "Now it's time to create the ML model. It is a simple CNN with 3 convolutional layers and 2 fully connected layers. The output is a single value between 0 and 1, which is the probability of the area being burned.\n",
    "Input size is 6x64x64 (6 bands, 64x64 pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a157f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the CNN model\n",
    "class BADNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BADNet, self).__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=3, stride=1, padding=1)  # Output size: 16x64x64\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)  # Output size: 16x32x32\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)  # Output size: 32x32x32\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)  # Output size: 32x16x16\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)  # Output size: 64x16x16\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)  # Output size: 64x8x8\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(in_features=64 * 8 * 8, out_features=256)  # Output size: 256\n",
    "        self.fc2 = nn.Linear(in_features=256, out_features=128)  # Output size: 128\n",
    "        self.fc3 = nn.Linear(in_features=128, out_features=1)  # Output size: 1\n",
    "        \n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(p=0.25)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Apply convolutional layers with ReLU activation and max pooling\n",
    "        x = self.pool1(F.relu(self.conv1(x)))  # Output size: 16x32x32\n",
    "        x = self.pool2(F.relu(self.conv2(x)))  # Output size: 32x16x16\n",
    "        x = self.pool3(F.relu(self.conv3(x)))  # Output size: 64x8x8\n",
    "        \n",
    "        # Flatten the output for the fully connected layers\n",
    "        x = x.view(-1, 64 * 8 * 8)  # Output size: 64 * 8 * 8 = 4096\n",
    "        \n",
    "        # Apply fully connected layers with ReLU activation and dropout\n",
    "        x = self.dropout(F.relu(self.fc1(x)))  # Output size: 256\n",
    "        x = self.dropout(F.relu(self.fc2(x)))  # Output size: 128\n",
    "        \n",
    "        # Final layer with sigmoid activation\n",
    "        x = torch.sigmoid(self.fc3(x))  # Output size: 1\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Sanity check\n",
    "model = BADNet()\n",
    "out = model(torch.rand(1, 6, 64, 64))\n",
    "print(f'Output shape: {out.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec52e251",
   "metadata": {},
   "source": [
    "Create the Lightning modulefor training, testing and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a4528b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitModel(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = BADNet()\n",
    "        self.criterion = nn.MSELoss()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        features, labels = batch\n",
    "        outputs = self(features)\n",
    "        loss = self.criterion(outputs, self.burntindex(labels))\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        features, labels = batch\n",
    "        outputs = self(features)\n",
    "        loss = self.criterion(outputs, self.burntindex(labels))\n",
    "        self.log('val_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "    \n",
    "    def burntindex(self, label):\n",
    "        bai = sum(label.flatten()) / (label.shape[0] * label.shape[1])\n",
    "        return bai\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7b4e3d",
   "metadata": {},
   "source": [
    "Create all datasets and loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c648bdec-1aa2-4735-82db-3c18bace3421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset = BadnetDataset(feature_file_path, label_file_path, chip_size=64, overlap=0)\n",
    "\n",
    "# Split the dataset into training, validation, and testing sets\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.15 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6020db2e",
   "metadata": {},
   "source": [
    "Initialize the model and the trainer and start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34f1443-f5d0-40d5-912b-a0e71658dfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "lit_model = LitModel()\n",
    "trainer = pl.Trainer(max_epochs=10, accelerator='auto')\n",
    "trainer.fit(lit_model, train_loader, val_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc-autonumbering": true,
  "toc-showcode": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
